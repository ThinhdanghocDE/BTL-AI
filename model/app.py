import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import json
from datetime import datetime

# --- C·∫§U H√åNH TRANG (ƒê·∫∂T L√äN ƒê·∫¶U TI√äN) ---
st.set_page_config(page_title="D·ª± ƒëo√°n G·ª≠i ti·ªÅn Ng√¢n h√†ng", layout="wide")

# --- T·∫¢I C√ÅC TH√ÄNH PH·∫¶N ƒê√É L∆ØU ---
# S·ª≠ d·ª•ng cache ƒë·ªÉ kh√¥ng ph·∫£i t·∫£i l·∫°i m√¥ h√¨nh v√† scaler m·ªói l·∫ßn t∆∞∆°ng t√°c
@st.cache_resource
def load_model():
    """T·∫£i m√¥ h√¨nh Keras ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán."""
    try:
        model = tf.keras.models.load_model('C:/Users/ADMIN/Documents/AI/AI&ML (2)/model/final_model.h5')
        return model
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
        return None

@st.cache_resource
def load_scalers_and_info():
    """T·∫£i c√°c scaler v√† th√¥ng tin c·ªôt."""
    try:
        robust_scaler = joblib.load('C:/Users/ADMIN/Documents/AI/AI&ML (2)/model/robust_scaler.pkl')
        min_max_scaler = joblib.load('C:/Users/ADMIN/Documents/AI/AI&ML (2)/model/min_max_scaler.pkl')
        with open('C:/Users/ADMIN/Documents/AI/AI&ML (2)/model/final_columns.json', 'r') as f:
            final_columns = json.load(f)
        with open('C:/Users/ADMIN/Documents/AI/AI&ML (2)/model/age_group_map.json', 'r') as f:
            age_group_map = json.load(f)
        return robust_scaler, min_max_scaler, final_columns, age_group_map
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i c√°c th√†nh ph·∫ßn ti·ªÅn x·ª≠ l√Ω: {e}")
        return None, None, None, None

# T·∫£i t·∫•t c·∫£ c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt
model = load_model()
robust_scaler, min_max_scaler, final_columns, age_group_map = load_scalers_and_info()


# --- GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG STREAMLIT ---
st.title("Ô∏èüè¶ ·ª®ng d·ª•ng D·ª± ƒëo√°n Kh·∫£ nƒÉng G·ª≠i ti·ªÅn c·ªßa Kh√°ch h√†ng")
st.write("Cung c·∫•p th√¥ng tin c·ªßa kh√°ch h√†ng ƒë·ªÉ m√¥ h√¨nh d·ª± ƒëo√°n kh·∫£ nƒÉng h·ªç s·∫Ω ƒëƒÉng k√Ω m·ªôt kho·∫£n ti·ªÅn g·ª≠i c√≥ k·ª≥ h·∫°n.")

# T·∫°o c√°c c·ªôt ƒë·ªÉ b·ªë tr√≠ giao di·ªán
col1, col2, col3 = st.columns(3)

with col1:
    st.header("Th√¥ng tin c√° nh√¢n")
    age = st.number_input("Tu·ªïi", min_value=18, max_value=100, value=40)
    job_options = ['management', 'technician', 'blue-collar', 'admin.', 'retired', 'No Income', 'Unstable Income']
    job = st.selectbox("Ngh·ªÅ nghi·ªáp", options=job_options)
    marital = st.selectbox("T√¨nh tr·∫°ng h√¥n nh√¢n", options=['married', 'single', 'divorced'])
    education = st.selectbox("H·ªçc v·∫•n", options=['tertiary', 'secondary', 'primary', 'unknown'])

with col2:
    st.header("Th√¥ng tin t√†i ch√≠nh li√™n h·ªá")
    balance = st.number_input("S·ªë d∆∞ t√†i kho·∫£n (Dolla)", value=1000)
    default = st.selectbox("C√≥ n·ª£ x·∫•u kh√¥ng?", options=['no', 'yes'])
    housing = st.selectbox("C√≥ vay mua nh√† kh√¥ng?", options=['yes', 'no'])
    loan = st.selectbox("C√≥ vay c√° nh√¢n kh√¥ng?", options=['yes', 'no'])
    contact = st.selectbox("Ph∆∞∆°ng th·ª©c li√™n h·ªá", options=['cellular', 'telephone', 'unknown'])


with col3:
    st.header("Th√¥ng tin chi·∫øn d·ªãch")
    duration = st.number_input("Th·ªùi gian cu·ªôc g·ªçi", min_value=0, value=300)
    campaign = st.number_input("S·ªë l·∫ßn li√™n h·ªá trong chi·∫øn d·ªãch n√†y", min_value=1, value=2)
    month_name = st.selectbox("Th√°ng li√™n h·ªá cu·ªëi c√πng",
                               options=['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])
    pdays = st.number_input("S·ªë ng√†y k·ªÉ t·ª´ l·∫ßn li√™n h·ªá cu·ªëi c√πng (nh·∫≠p -1 n·∫øu ch∆∞a li√™n h·ªá)", min_value=-1, value=-1)
    previous = st.number_input("S·ªë l·∫ßn li√™n h·ªá tr∆∞·ªõc chi·∫øn d·ªãch n√†y", min_value=0, value=0)
    poutcome = st.selectbox("K·∫øt qu·∫£ c·ªßa chi·∫øn d·ªãch tr∆∞·ªõc", options=['success', 'failure', 'other', 'unknown'])

# N√∫t d·ª± ƒëo√°n
if st.button("D·ª± ƒëo√°n üöÄ", use_container_width=True):
    if model and robust_scaler and min_max_scaler and final_columns and age_group_map:
        # --- B∆Ø·ªöC 1: T·∫†O DATAFRAME T·ª™ D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO ---
        input_data = {
            'job': [job],
            'marital': [marital],
            'education': [education],
            'default': [default],
            'balance': [balance],
            'housing': [housing],
            'loan': [loan],
            'contact': [contact],
            'month': [datetime.strptime(month_name, "%b").month],
            'duration': [duration],
            'campaign': [campaign],
            'pdays': [pdays],
            'previous': [previous],
            'poutcome': [poutcome],
        }
        input_df = pd.DataFrame(input_data)

        # Th√™m c·ªôt tu·ªïi g·ªëc ƒë·ªÉ x·ª≠ l√Ω
        input_df['age'] = [age]

        # --- B∆Ø·ªöC 2: TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU (Y H·ªÜT NOTEBOOK) ---

        # 2.1. X·ª≠ l√Ω nh√≥m tu·ªïi (age_group)
        bins = [18, 30, 40, 50, 100]
        labels = ['18-30', '31-40', '41-50', '51-61']
        input_df['age_group'] = pd.cut(input_df['age'], bins=bins, labels=labels, right=False).astype(str)
        input_df.drop('age', axis=1, inplace=True)

        # 2.2. √Åp d·ª•ng Target Encoding cho age_group
        input_df['age_group'] = input_df['age_group'].map(age_group_map)

        # 2.3. Chu·∫©n h√≥a c√°c c·ªôt s·ªë
        input_df['balance'] = robust_scaler.transform(input_df[['balance']])
        numeric_cols_to_scale = ['duration', 'campaign', 'pdays', 'previous']
        input_df[numeric_cols_to_scale] = min_max_scaler.transform(input_df[numeric_cols_to_scale])
        input_df['pdays'] = input_df['pdays'].replace(-1, 0) # X·ª≠ l√Ω pdays = -1

        # 2.4. M√£ h√≥a c·ªôt nh·ªã ph√¢n
        binary_cols = ['default', 'housing', 'loan']
        for col in binary_cols:
            input_df[col] = input_df[col].map({'yes': 1, 'no': 0})

        # 2.5. √Åp d·ª•ng One-Hot Encoding
        input_df_encoded = pd.get_dummies(input_df)

        # 2.6. S·∫Øp x·∫øp l·∫°i c√°c c·ªôt ƒë·ªÉ kh·ªõp v·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán
        # T·∫°o m·ªôt DataFrame tr·ªëng v·ªõi ƒë√∫ng c√°c c·ªôt
        final_df = pd.DataFrame(columns=final_columns)
        # ƒêi·ªÅn d·ªØ li·ªáu t·ª´ input ƒë√£ m√£ h√≥a v√†o
        final_df = pd.concat([final_df, input_df_encoded], ignore_index=True).fillna(0)
        # ƒê·∫£m b·∫£o th·ª© t·ª± c·ªôt ch√≠nh x√°c
        final_df = final_df[final_columns]

        # --- B∆Ø·ªöC 3: D·ª∞ ƒêO√ÅN ---
        prediction_proba = model.predict(final_df)
        prediction = (prediction_proba > 0.4).astype(int) # S·ª≠ d·ª•ng ng∆∞·ª°ng t·ªëi ∆∞u c·ªßa b·∫°n

        # --- B∆Ø·ªöC 4: HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
        st.subheader("K·∫øt qu·∫£ D·ª± ƒëo√°n")
        probability = prediction_proba[0][0]

        if prediction[0] == 1:
            st.success(f"**Kh√°ch h√†ng c√≥ kh·∫£ nƒÉng s·∫Ω g·ª≠i ti·ªÅn.** (X√°c su·∫•t: {probability:.2%})")
            st.balloons()
        else:
            st.error(f"**Kh√°ch h√†ng c√≥ kh·∫£ nƒÉng s·∫Ω KH√îNG g·ª≠i ti·ªÅn.** (X√°c su·∫•t kh√¥ng g·ª≠i: {1-probability:.2%})")
        with st.expander("Xem chi ti·∫øt d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"):
            st.dataframe(final_df)
    else:
        st.error("M√¥ h√¨nh ho·∫∑c c√°c th√†nh ph·∫ßn ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ki·ªÉm tra l·∫°i file.")